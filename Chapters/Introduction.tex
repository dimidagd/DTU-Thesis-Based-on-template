\chapter{Introduction}
\section{Problem statement}
\subsection{Autonomy at sea}
Autonomy at sea is a challenging problem that requires a multi-fold merging of different engineering branches. A specific domain of interest is that of enabling a system to intelligently understand the environment around it, or else maintain \emph{situational awareness}. This is a key component in most intelligent autonomous systems architectures, since it provides the context on which decision making modules are based on.
%Autonomy at sea has the potential of providing many-fold solutions and benefits to existing financial, human-safety or ecological considerations.

%\subsubsection{}
%\emph{Financially}, autonomy at sea can reduce crew costs, especially over long transport distances, and result in better fuel economy through optimized decisions. While one could argue that the construction cost of an autonomous ship increases due to sophisticated and complex systems onboard, it might also turn out that fully autonomous vessels can be constructed with lower investment cost, due to the lack of need to provision for crew accommodation, crew safety equipment, bridge support, and all the functionalities that maintaining human quality of life onboard. The potential crew cost savings span in a broad spectrum, depending on the type of ship and its function, but in general it is estimated that crew costs account for a substantially large proportional of a ship's operation, whether that be a cargo, passenger, supply or research vessel.
\subsubsection{Regulations}
Navigators are assumed to adhere to established regulations for preventing collisions at sea. \emph{International Regulations for Preventing Collisions at Sea(COLREG)} defines a set of rules that regulate navigational behavior for various situations encountered at sea, including visual and audio signaling,  as well as expected maneuvering behaviors. Nevertheless, due to the endless number of parameters describing a particular situation, such as different berth depths, confined water-space, possible physical obstructions, different ship maneuverability abilities, weather conditions, only to name a few, even COLREG do not define the absolute right of way. The rules are in many cases open to interpretation and while in ports, there exists an air traffic controller equivalent, namely a \emph{vessel traffic controller} that helps in avoiding collisions, each navigator is \textit{"expected to assume responsibility for traversing the seas in a safe manner"}. According to a report issued by the \emph{European Maritime Safety Agency(EMSA)}, more than 18.000 collision incidents have been reported within a five-year time frame(2011-2016). The human and capital losses reported in \cref{fig:losses,fig:distribution} signify only but a fraction of the potential impact that autonomy at sea can provide.

% An effective holistic autonomous shipping ecosystem, minimizes accidents caused by human errors, while at the same time increasing the capacity of current carriage or transport
\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\textwidth]{Europe-Ship-Safety.jpg}
	\caption{Recorded maritime incidents from 2011 to 2016 – Credit: EMSA}.
	\label{fig:losses}
\end{figure}


\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\textwidth]{Distribution-of-Incidents.jpg}
	\caption{Geographic distribution of maritime incidents in EU from 2011 to 2016– Credit: EMSA}
	\label{fig:distribution}
\end{figure}

\subsection{Situational awareness}
Creating an intelligent vessel of equivalent or better --- compared to conventionally operated vessel--- performance and safety capabilities, requires the development of reliable \emph{navigational situational awareness}. Endsley  \cite{Endsley1995} defines situational awareness as “the perception of elements in the environment within a volume of time and space, the comprehension of their meaning, and the projection of their status in the near future.”  In addition, Endsley defined a well-known theoretical model for situational awareness  \cite{Endsley2001,Endsley1995} comprising of three distinct levels.

\begin{itemize}
	\item Level 1 SA, \emph{Perception of the elements in the environment}. Identifying relevant elements in the environment, along with their attributes --- e.g. dynamics or status --- is the most basic level of SA. Essentially this level is about being aware of the elements --- such as moving objects, events, people, or systems in general --- and their current states(e.g. location, condition, modes, actions). Level 1 SA therefore, besides elements recognition, also involves their on-going monitoring as they change over time. 
	\item Level2 SA, \emph{Comprehension of the current situation}: This level of SA involves the synthesis elements in order to Comprehending a situation. This level is therefore integrating the information perceived from Level 1 SA in order to understand the significance of individual elements on the desired \emph{goals or outcomes}. Through the processes of pattern recognition, interpretation, and evaluation, Level 2 SA results in a holistic understanding of the environment that allows for the comprehension of the significance of elements and events.
	\item Level 3 SA, Projection of future status of the situation: This is the highest level of SA and includes the ability to predict  the future status of elements in the environment. Thus, given the outcome of Perception and Comprehension(Level 1 and 2 SA), as well as knowledge about the dynamical interaction of the elements, Level 3 SA can use this information  to make predictions about the future states of the environment that can be useful in the decision making process.
\end{itemize}


The engineering challenges in achieving each of the aforementioned levels highly depends on the context of the related situation or scenario. Thus, the information necessary to achieving SA for an aircraft pilot is totally different from what is required for a power plant operator, as is the information necessary for public health authorities to maintain situational awareness during a pandemic. \emph{The scope of this thesis is to evaluate Level 1 SA, in the context of situational awareness at sea.}

Developing \emph{situational awareness at sea} is not a trivial problem to solve, as one is challenged to imitate the performance of an experienced seafarer, in accessing the numberless parameters as perceived through a navigator's senses(mostly vision), aided by the interfaced instruments onboard, and making optimal decisions despite the limited amount of certainty. A decisive factor in the effectiveness of this imitating process, is that  an \emph{autonomous system} has information abundance, being directly exposed to the full volume of data available from the sensors , and hence it has the potential of perceiving the environment with better accuracy than a human can through the limited communication bandwidth of human-machine interfaces and the small accuracy of ones senses. Where humans clearly outperform machines at, is combining abstract sensed information and life experience, in perceiving a scene. For all the abundant information available onboard, through for instance multiple cameras spanning 360 degrees around a vessel, or through the radar and laser sensors that can provide sub-centimeter accuracy, the actual potential of the full volume of the data does not  fully unfold , unless one intelligently combine the different \emph{sensor modalities} that accompany the individual sensory information. This intelligent data handling, is in many cases referred to as \emph{Sensor Fusion}.


\begin{figure}[H]
	\centering
	\includegraphics[width=.7\textwidth]{munin_shore_satellite_autonomous_ship_control_robotics.JPG}
	\caption{Situational awareness courtesy of  \cite{MUNIN}}
	\label{fig:situation}
\end{figure}



\begin{figure}[H]
	\centering
	\includegraphics[width=0.6\textwidth]{less_is_more.png}
	\caption{Information gap between data produced and needed information  \cite{Endsley1995}.}
	\label{fig:less_is_more}
\end{figure}

\subsection{Sensor fusion}
Although \emph{Sensor Fusion} is considered to be a modern concept, it has existed since the ancient times and in different forms. Seafarers traveling long distances, relied on a navigational technique known as "\emph{dead reckoning}", which is simply a fusion of a magnetic compass, a chronometer and a speed estimation in order to derive a ship's relative latitude and longitude given a known starting point. Taking it even further, a sextant is, even nowadays, used to localize a ship with respect to a map of celestial bodies using the instruments bearing measurements. All of these techniques were performed by humans onboard ships long before the first computer even existed. Sensor fusion in the context of developing situational awareness at sea, is the ability to bring together inputs from multiple radars, lidars and cameras onboard, external or internal GNSS sensors, to form a single model or image of the environment around the vessel. The resulting model is more accurate because it balances the strengths of the different sensors. An intelligent navigation system can then use the information provided through sensor fusion to support more-intelligent actions.
\subsubsection{Modalities}
Each sensor used onboard has inherent strength and weaknesses.  While a \emph{radar sensor} is very capable in determining relative distance, bearing and range-rate --- even in challenging conditions ---, it's resolution and lack of contextual information does not allow one to extract abstract features, such as the class of an observed object. \emph{Camera sensors} on the other hand, can provide the context information required to perform classification tasks, however they can be easily influenced by the varying environmental conditions, such as dirt, rain or extreme dynamic lighting conditions. \emph{Laser sensors} have been successfully used both for classification and localization of objects, but in general do not share the range or affordability of a camera or a radar sensor. Cooperative objects are equipped with electronic navigation sensors that are used to estimate the position of the ship, usually a global navigation satellity system (GNSS) or an inertial sensor, and radio equipment for communication purposes. An example of a cooperative system is the \emph{Automatic Identification System (AIS)}. This additional sensed information, such as a ship's absolute position, its identification code and more navigational data are being broadcasted to other ships through VHF channels.

\begin{figure}[H]
	\centering
	\includegraphics[width=1.0\linewidth]{"sensorsProsCons"}
	\caption{Different sensor strengths and characteristics}
	\label{fig:SensorProsCons}
\end{figure}



While undoubtedly useful, cooperative systems alone are not reliable enough for developing situation awareness because of the diversity of surveillance scenarios, and the presence of non-cooperative targets. As an example, in scenarios considering illicit activities, the transmitted cooperative data can be counterfeit, malicious, masked or not transmitted at all. At the same time, small ships are not enforced by maritime regulations to carry AIS equipment. 

It turns out thus, that maintaining Situational Awareness solely on cooperative information is challenging and in order to resolve non-cooperative scenarios on has to rely on remote sensing equipment, such as radars or cameras. Jointly, AIS data along with radar data propose an interesting solution for ship detection, identification and tracking.


\subsection{Scope}


A foundational aspect of sea domain awareness is the ability to identify and accurately track the state of multiple target ships as well as one's own-ship state. Therefore, the scope of this thesis comprises of developing a \emph{ship tracking framework} , by implementing sensor fusion techniques found in literature.

Data fusion techniques can be classified into three main categories  \cite{nedo2013}:
\begin{itemize}
	\item Data association
	\item State estimation
	\item Decision fusion
\end{itemize}

 The focus of the thesis thus will be \begin{mylist}
	\item State estimation
	\item Data association
\end{mylist}
techniques. The performance of the framework should be validated both on simulated as well as on real datasets collected by DTU Elektro during sea trials.

\subsubsection{State estimation}
Concerning state estimation, both linear and non-linear observers are developed, namely Kalman Filtering(KF), Extended Kalman Filtering(EKF) and Particle Filtering(PF). The performance, limitations and qualitative characteristics of the aforementioned approaches are being compared against each other in an effort to provide an argument about the suitability of each approach to the problem at hand, and identify their strengths and weaknesses.
\subsubsection{Data association}
Solving the data association problem requires defining the set of observations that correspond to each individual tracked target as illustrated in \cref{fig:MultipathDA} .


\begin{figure}[H]
	\centering
	\includegraphics[width=0.6\textwidth]{DataAssociation2.jpg}
	\caption{ Multipath data association problem \cite{Lan2019}.}.
	\label{fig:MultipathDA}
\end{figure}

In the scope of the current thesis, the functionalities of the mentioned \emph{state-estimation} approaches are extended to handle multiple targets and clutter measurements by using statistical tools such as \emph{measurement gating},leading to approximate solutions known in literature as Probabilistic Data Association Filtering(PDAF). 

\subsection{Past research}
Efforts in improving maritime surveillance have been spanning across different directions in the past. Concerning  AIS radar data fusion,  \cite{Habtemariam2015}  \cite{Heymann2015} have documented the effectiveness of this approach. Concerning military applications, NATO appears to have been a major driver in the related research effort \cite{Guerriero2008,9781586035365}. The Autosea project(NTNU)  \cite{Brekke2019}has provided considerable research effort in exploring sensor fusion for autonomous surface vehicles.
\subsection{Key literature}
\subsubsection{Tracking}
This reading is heavily influenced by existing research in the related fields. Concerning target tracking,  \emph{Y. Bar Shalom} \Cite{BarShalom1980,Shalom1990,Shalom2001} has laid the foundations upon which most modern Target Tracking Systems rely on to extract and fuse remote sensor information in order to track cooperative or non-cooperative targets. His work considers disturbances like measurement errors, clutter, target maneuvering and interfering sources of information.  Y.Bar-Shalom has published more than 550 papers, 8 books, 20 book chapters and has over 35,000 citations. \\
\subsubsection{Coordinate systems}
Concerning coordinate systems, most of the equations and transformations found in the related chapters are based on the work of \emph{Jay A. Farrell} in \cite{Farrell2008}.\\

\subsubsection{Probabilistic framework and modeling}
\emph{Sebastian Thrun} in \cite{Thrun2005} has provided seminal knowledge and paved the way during 2005 in what is considered today a domain of expertise in robotics, namely \emph{Probabilistic Robotics}. The author of this reading is heavily influenced by Sebastian's contributions on using calculus and probability theory to represent ambiguity and degree of belief in an analytical and mathematically sound way. 

\subsection{Project limitations due to COVID19 lock down}
The \emph{DTU ShippingLab} team had planned to support this MSc project with data from W-band radar (77-81 GHz) and with camera-detected objects. Due to the lock down following the COVID-19 pandemic crisis in 2020, these sea tests could not be conducted until mid-June 2020. Homographies that should translate camera detected objects from pixel frame to estimate of geographical positions were in need of these data as well. 


\begin{figure}[h!]
	\centering
	\captionsetup{width=0.45\textwidth}
	\begin{minipage}{0.49\textwidth}
		\centering
		\includegraphics[width=0.95\textwidth]{Pictures/cover2}
		\caption{TUCO test vessel.}\label{fig:cover2}
	\end{minipage}
	\begin{minipage}{0.49\textwidth}
		\centering
		\includegraphics[width=0.95\textwidth]{Pictures/cover3}
		\caption{Front mast.}\label{fig:cover3}
	\end{minipage}
	%\caption{Photographs taken during June 2020 sea trials.}\label{fig:coverA}
\end{figure}


There are hence some limitations in the data that could be made available for this project, but the following sea data have been included: X-band radar, AIS, GNNS compass information: heading, course over ground and speed over ground as well as position of own ship.

The scope of the thesis is multi-modal sensor fusion although the Corona situation has prevented the use of some real data. 
The picture in \Cref{fig:stack} shows the ShippingLab test vessel from TUCO equipped with the full set of sensors. The foremost mast is dedicated to ShippingLab Autonomy sensors. The sea test took place in mid June 2020, with a three-months delay.





%
%\begin{figure}[h!]
%	\centering
%	%\captionsetup{width=0.45\textwidth}
%	\begin{minipage}{0.8\textwidth}
%		\centering
%		\includegraphics[width=0.95\textwidth]{Pictures/cover4}
%		\caption{}
%		%\captionof{figure}{captionfig1}\label{fig:cover4}
%	\end{minipage}
%	\hfill
%	\begin{minipage}{0.8\textwidth}
%		\centering
%		\includegraphics[width=0.95\textwidth]{Pictures/cover5}
%		\caption{}
%		%\captionof{figure}{captionfig2}\label{fig:cover5}
%	\end{minipage}
%	\caption{Sea trials, June 2020}\label{fig:coverB}
%\end{figure}
%


