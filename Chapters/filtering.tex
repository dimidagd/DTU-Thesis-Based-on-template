\chapter{Filtering}
\section{Introduction}
All sensors are noisy to some extend depending on the actual sensor, the data processing algorithms, or the enviromental conditions. At the same time, while at sea there is no guarantee that all the sensors are producing useful observations. There is a need thus to leverage the characteristics of every sensor when tracking a remote ship, in combination with knowledge about a ship's kinematic model, in order to produce estimates of better quality than when relying solely on a sensor output. Bayesian techniques have traditionally been very effective at providing the probabilistic framework under which such fusion algorithms are developed. The purpose of this chapter is thus to give an overview of a limited number of filtering techniques that were tested both in simulated and in real multi-sensor scenarios.

%modeling of the noise behavior is a non-trivial process that is out of the scope of this reading. In the context of this reading all noise is assumed to be zero-mean(de-biased) and additive in the sensors output.  
\section{Approach}
To obtain kinematic components of a moving target such as position, velocity and acceleration, the predominant method in target tracking is using stochastic estimation approaches. A moving target is described by a state-space dynamic model driven by white process noise, and mean-square estimates are calculated using noisy measurements. Models of this kind constitute the basis of Kalman Filters, which are the basic algorithms in target tracking, either as single filters or used as modules of a more complex algorithm. Many algorithms have also been developed trying to tackle nonlinearities, multiple target tracking or observation association \cite{Ekstrand2012}.

For the case of a linear system with a known state transition matrix and additive white Gaussian process noise, the classic Kalman Filter provides an optimal estimate in terms of minimum mean square error (\emph{MMSE}). However, for non-linear systems, state-estimation remains a challenging problem attracting intense research interest. Optimal nonlinear filters are often infinite dimensional and thus difficult to implement and computationally intractable. In a deterministic framework, optimal nonlinear observers are available when the systems exhibit a special structure \cite{Krener1985} , however in general nonlinear filtering cases, approximate and computationally tractable solutions are used in practice \cite{Daum2005}.

Approximate nonlinear filters can be subdivided into two classes depending on the representation form of the probability distributions. Filters in the first class are based on analytically or numerically linearizing the motion and observation models. The standard Kalman filter is then applied to the linearized state and measurement equations evaluated at an operating point. The operating point is chosen as the best current estimate based on the linearized system with the expectancy of being close to the true state \cite{Shalom2001}. The Extended Kalman Filter (EKF) belongs to this class of filters, and is a computationally effective algorithm finding applications in many areas such as motor control \cite{Terzic2001}, power system analysis \cite{Khazraj2016}, weather forecasting \cite{Rosnay2012}, and target tracking which is the main focus of this writing \cite{Shalom1995}. The alternative class of nonlinear filters use Monte Carlo Sampling to approximate the actual state's probability distribution.  A particle filter (PF) is propagating the sampled distribution through the nonlinear motion model and then re-samples the distribution based on the likelihood of measurement models. 

Both approaches do not tackle directly a fundamental issue in target tracking, that of data-association. In most tracking situations, sensors provide measurements both for the target of interest as well as for different targets/noise present in the environment. Filtering frameworks need to be able to handle this additional lack of information. Probabilistic Data Association \cite{Ristic2004} variants of the EKF and PF effectively tackle this problem by leveraging systematic knowledge of a \emph{clutter-model} and making intelligent decisions between the uncertainty levels of the estimated states and the observations inherent noise models.

This section is thus devoted to:

\begin{description}[style=nextline]
	\item[Linear filters] Kalman Filters.
	\item [Non-linear filters]
	\begin{itemize}
		\item[]
		\item[EKF] Extended Kalman Filters
		\item[PF]Particle Filters
		\item[PDAF] Probabilistic Data Association Filters 
	\end{itemize}
	\item[Comparison]Performance and suitability analysis of the different filters. 
\end{description}


\section{Kalman Filters}

\begin{itemize}
	\item System's state evolution $\mathbf{x}_{k+1} = f(\mathbf{x}_k,u_k) + w_{\textit{x}}$ is linear and driven by
	\begin{itemize}
		\item Known input $u_k$
		\item Additive process noise $w_{\textit{x}}$ which is assumed to be a zero-mean, white and uncorrelated with known covariance matrix $Q(k)$
	\end{itemize}
	\item The observations $ \observ_k = h(\mathbf{x}_k,u_k) + \measnoise $  are linear functions of the state vector and the input vector with $\measnoise$ being additive zero-mean white Gaussian noise with known covariance matrix $\measCov(k)$
	
	\item The \emph{initial state} vector is a random variable with known mean $\mathbf{x}_0$ and covariance $P_0$ (initial uncertainty)
\end{itemize}


\begin{figure}[H]
	\centering
	\includegraphics[width=0.6\textwidth]{/Users/dimda/static_web/static/thesis/KF2.png}
	\caption{Block diagram of a discrete Kalman filtering algorithm}.
	\label{fig:state_vector}
\end{figure}

\subsection{Mean Squared Error (MSE)}
In statistics and signal processing, \emph{Mean Squared Error} is a common measure of an estimator's performance and it measures the average of the squares of the errors, or else, the average squared difference between the estimated values and the actual value(ground truth). MSE thus is a cost function, corresponding to the \emph{expected value} of the squared error loss. MSE is always non-negative, and values closer to zero are considered better. The MSE of an estimator $\hat{\theta}$ with respect to an unknown parameter $\theta$ is defined as 

\[ MSE(\hat{\theta}) = E_{\theta}\left[(\hat{\theta}-\theta)^2\right] \]

Under the above assumptions the Kalman Filter is the \emph{minimum mean square error }(MMSE) state estimator. If the random variables are \emph{not Gaussian}, but one can still obtain their first two moments, then the KF is still the \emph{best \textbf{linear} MMSE estimator} \cite{Shalom1995}.

\subsection{Kalman Filter limitations}

For all its powerful characteristics, such as optimality and robustness, the \emph{Kalman Filter} algorithm is not flexible enough to accommodate target tracking \cite{Shalom1995} since

\begin{itemize}
	\item Trigonometric functions lead to
		\begin{itemize}
			\item Nonlinear motion models
			\item Nonlinear observation models
		\end{itemize}
	\item It is unable to capture mode transitions(target maneuvering after being stationary)
	\item It is a single target \& unimodal method
\end{itemize}

The above problems usually lead to filter divergence, that is the Mean Squared Error grows unbounded over time.

\section{Extending the Kalman Filter}

When either the system dynamics, or the observation dynamics is non-linear, the probability density functions that provide the MMSE are no longer Gaussian. An optimal non-linear filter propagates the density functions and evaluates their statistical properties, a process which is usually not analytically or even computationally tractable. The \emph{Extended Kalman Filter}(EKF) is a sub-optimal state estimation algorithm for nonlinear systems. It is the \emph{nonlinear version} of the \emph{Kalman Filter}, and while it is implementing a Kalman Filter under the hood, the distinctive difference is that it does so on the system dynamics that result from the re-linearization of the original non-linear system around the latest state estimate.
\subsection{EKF Modeling assumptions}

\begin{itemize}
	\item Same as the KF except that the state transition function $f(\cdot)$ and/or the measurement function $h(\cdot)$ are nonlinear. Note that the noise sources are still assumed to enter additive into the state update/measurement equations.
	\item Approximating the nonlinear functions $f(\cdot),h(\cdot)$ using a  \emph{First order Taylor expansion} is a reasonable approximation to the original function.
\end{itemize}

\subsection{Taylor approximation of the CTRV model}

The Constant Turn Rate and Velocity model can be approximated using a 1st order Taylor approximation around an operating point. This process involves the analytical \emph{Jacobian} calculation of a vector function, a usually trivial process in compact low-order systems.


The discrete nonlinear motion model $x_{k} = f({x}_{k-1})$ can be linearized around a known prior state $x_{k-1}$ as in \Cref{eq:linearization_jacob}




\begin{equation}
\label{eq:linearization_jacob}
f_{k-1} \approx F_{k-1} =
\begin{bmatrix}
\nabla_{x_{k-1}} f_{k-1}^{T}(x_{k-1})
\end{bmatrix}_{x_{k-1} \rightarrow\text{latest estimate}}^{T}
\end{equation}


and for the \emph{CTRV} motion model in specific, this leads to \Cref{eq:linearization_mot_model}




\begin{equation}
\label{eq:linearization_mot_model}
F_{{CTRV}_{k-1}} =
\begin{bmatrix}1 &0 &\frac{sin(\heading+T\omega) - \sinh}{\omega} & \boatspeed \frac{cos(\heading+T\omega)-cosh}{\omega} & \boatspeed\frac{sinh -sin(\heading+T\omega) + T\omega cos(\heading+T\omega)}{\omega^{2}}\\\\
0 &1 &-\frac{cos(\heading+T\omega) - cos(\omega)}{\omega} &\boatspeed \frac{sin(\heading+T\omega)-sinh}{\omega} & \boatspeed\frac{cos(h + T\omega) -cosh + T\omega sin(\heading+T\omega)}{\omega^{2}}\\\\
0 &0 &1 &0 &0 \\\\
0 &0 &0 &0 &1\end{bmatrix}
\end{equation}


\subsection{Taylor approximation of the observation models}


Similarly, a measurement model $\observ_k=h(\mathbf{x_k})$ can be linearized around the state $x_{k}$ as in \Cref{eq:linearize_jacobian2}


\begin{equation}
\label{eq:linearize_jacobian2}
h_{k} \approx H_{k} =
\begin{bmatrix}
\nabla_{x_{k}} h_{k}^{T}(x_{k})
\end{bmatrix}_{x_{k} \rightarrow\text{motion updated estimate}}^{T}
\end{equation}

For example, the \emph{radar model} that measures distance and bearing  to a target around the target's state vector $\mathbf{x}_k = [x,y,\boatspeed,h,\turnrate]^T$, can be linearized as in \Cref{eq:linearize_radar}:


\begin{equation}
\label{eq:linearize_radar}
H_k =
\begin{bmatrix}
\frac{x}{\sqrt{x^2+y^2}} &\frac{y}{\sqrt{x^2+y^2}} &0 &0 &0 \\\\
-\frac{y}{x^2+y^2} &\frac{x}{x^2+y^2} &0 &0 &0
\end{bmatrix}
\end{equation}

\subsection{Limitations}

The quality of approximating the state transitions and measurements using Taylor expansions depends on two main factors. 


At first, the degree of non-linearity of the functions that are being approximated. If the manifold is generally smooth and close to being linear, then the Taylor approximation is fair enough, and an Extended Kalman Filter can approximate the posterior probability distributions with sufficient accuracy. However, the functions can besides non-linear be multi-modal, in which case a Taylor expansion might be a poor approximation. 


The accuracy of the approximation at a second level depends on the compactness of the probability distributions. The less certain one is about the current estimate, the wider the Gaussian belief, and the more the nonlinearities or the multiple modalities affect the state transition and measurement functions (\Cref{fig:taylor_approximation,fig:taylor_approximation2}).

\begin{figure}[H]
	\centering
	\includegraphics[width=0.6\textwidth]{/Users/dimda/static_web/static/thesis/EKF_lineariation_error.png}
	\caption{Gaussian PDF propagation through a nonlinear model and Taylor-approximations \cite{Thrun2005}.}.
	\label{fig:taylor_approximation}
\end{figure}


\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\textwidth]{/Users/dimda/static_web/static/thesis/gaussian_error.png}
	
	\caption{Propagation error  of the Gaussian mean due to non-linearity. For a given non-linear function $h()$ the propagation error $e=\mathbf{E}[h(\mathbf{x})]-h(\mathbf{E}[\mathbf{x}])$ is large for Gaussians with larger variance \textit{(thick line, left)} and unnoticeable for narrow Gaussians\textit{(thin line, right)} \cite{Sola2011}.}
		
	\label{fig:taylor_approximation2}
\end{figure}


\begin{figure}[H]
	\centering
	\includegraphics[width=1\textwidth]{/Users/dimda/static_web/static/thesis/non_linearities_multi.png}
	\caption{Non-linear mappings of a MISO function $\observ=h(x,y) = x \cdot sin(y)$ for different probability regions. The more elliptic the projected shapes, the more linear the function around the linearization point. Again a small probability region gives a good linear approximation whereas a larger region bends the ellipse over the surface, implying higher approximation errors \cite{Sola2011}.}
	\label{fig:nonlinearitiesmulti}
\end{figure}

\section{Particle Filter}
\subsection{Monte Carlo Methods}
\emph{Particle filters} (PF) belong to the category of sub-optimal filters. They represent probability densities with point mass densities (particles), and perform \emph{Sequential Monte Carlo} (SMC) estimations. SMC ideas were historically introduced in statistics from the 1950s but the limited computational power available at the time constrained their use and development. As soon as faster computers were made available, the related research activity in the field increased, resulting in their improvement and adoption in numerous applications, namely tracking, localization of agents, pattern recognition, fault-detection, and Advanced Driver Assistance Systems(ADAS). 

\subsection{Monte Carlo Integration}
The basis Sequential Monte Carlo methods is \emph{Monte Carlo Integration}. If a multidimensional integral (\Cref{eq:MCI})needs to be evaluated 
\begin{equation}
\label{eq:MCI}
\mathbf{I} = \int \mathbf{g(x)} d\mathbf{x}
\end{equation}

where 

\begin{equation}
	 \mathbf{x} \in \mathbf{R}^{n_{x}} 
\end{equation}


Then the Monte Carlo (MC) approach for numerical integration assumes a factorization as in \Cref{eq:MCIfact}

\begin{equation}
\label{eq:MCIfact}\mathbf{g(x)} = \mathbf{f(x)} \cdot \pi(\mathbf{x}) 
\end{equation}


so  as that $\pi(\mathbf{x})$ is interpreted as a \emph{probability density function}, satisfying \Cref{eq:MCI2}

\begin{equation}\label{eq:MCI2}
\begin{aligned}
\pi(\mathbf{x}) \geq 0 \\
\int \pi \mathbf{x} d \mathbf{x} = 1
\end{aligned}
\end{equation}




If one can "draw" $N >> 1$ samples ${x^i; i = 1,...,N}$ distributed according to $\pi (\mathbf{x})$ , then the integral estimate can be approximated with the sample mean as in  \Cref{eq:MCI3}

\begin{equation}\label{eq:MCI3}
I = \int \mathbf{f}(\mathbf{x})\pi(\mathbf{x}) d\mathbf{x} = I_N \approx \frac{1}{N}\sum_{i=1}^{N} \mathbf{f}(\mathbf{x}^i)
\end{equation}


Given that the samples $\mathbf{x}^i$ are independent, then $I_N$ is an unbiased estimator, and according to the law of large numbers it will almost surely converge to $I$.


Under the assumption that the variance $\variance$ of $\mathbf{f}(\mathbf{x})$,  is finite

\[ \variance = \int (\mathbf{f}(\mathbf{x})- I)^2 \pi(\mathbf{x}) \]


then the central theorem holds and the estimation error converges to the distribution of \Cref{eq:MCI4}

\begin{equation}\label{eq:MCI4}
\lim_{N\rightarrow \inf} \sqrt{N}(I_N - I) \sim \mathcal{N}(0,
\variance)
\end{equation}


In the \textbf{\emph{Bayesian}} context, $\pi(\mathbf{x})$ conveniently corresponds to the \emph{posterior} belief density. What is not convenient though, is the fact that the posterior is usually multivariate, nonstandard and only known up to proportionality, thus distributed sampling is usually not available from it. A solution to this issue is the use of \emph{\textbf{Importance Sampling}}.

\subsection{Importance Sampling}

In order to generate samples directly from $\pi (\mathbf{x})$ and estimate $I$ using Monte Carlo integration, one can generate samples from a density $q(\mathbf{x})$, which is similar to $\pi(\mathbf{x})$. The probability distribution function $q(\mathbf{x})$ is usually referred to as \emph{\textbf{importance }}or \emph{\textbf{proposal}} \emph{density}.


The similarity between $\pi \text{ - } q $ is expressed as

\begin{equation}\label{eq:proposal1}
\pi(\mathbf{x}) > 0 \rightarrow q(\mathbf{x})>0 , \text{for all } \mathbf{x} \in R^{n_x}
\end{equation}

\Cref{eq:proposal1}  implies that $q(\mathbf{x})$ and $\pi(\mathbf{x})$ have the same support.

Then the integral $I$ can be rewritten as

\begin{equation}\label{eq:MCIntegral}
I = \int \mathbf{f}(\mathbf{x}) d\mathbf{x} = \int f(\mathbf{x}) \frac{\pi(\mathbf{x})}{q(\mathbf{x})}q(\mathbf{x}) d\mathbf{x}
\end{equation}


Applying the \emph{Monte Carlo Sample Mean} to \Cref{eq:MCIntegral} leads to  \Cref{eq:MCSM}, where the \emph{particle importance weights} represent a \emph{Probability Mass Function}(PMF), and thus need to be normalized according to \Cref{eq:weight_normalize}.




\begin{equation}\label{eq:MCSM}
	I_N = \frac{1}{N} \sum_{i=1}^{N} \mathbf{f}(\mathbf{x}^i) \tilde{w}(\mathbf{x}^i)
\end{equation}



\begin{equation}\label{eq:weight_normalize}
w(\mathbf{x}^i)  \frac{\tilde{w}(\mathbf{x}^i)}{\sum_{j=1}^N \tilde{w}(\mathbf{x}^j)}
\end{equation}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\textwidth]{/Users/dimda/static_web/static/thesis/MC_importance.png}
	\caption{1-D Belief representation with weighted particles \cite{Rao2013}.}
	\label{fig:1d_belief}
\end{figure}

\subsection{Bayesian Estimation}

As already mentioned, in the Bayesian context, the distribution of interest $\pi (\mathbf{x})$ is the posterior density. For selecting the proposal distribution $q(\mathbf{x})$ it makes sense to try to maintain a degree of similarity between the proposal and the posterior, so that the finite $N$ selected $\mathbf{x}^i$ samples fall into probable regions of the posterior, that is regions that contain information about the actual posterior distribution $p(\mathbf{x} | \observ_i)$ and not around the distribution's tail.
\subsection{Sequential importance Sampling}


Intuitively, a recursive Bayesian nonlinear filter is a very suitable domain for applying \emph{Monte Carlo Integration}. This \emph{Sequential Monte Carlo} approach is known with various names \cite{Ristic2004} such as,

\begin{itemize}
	\item Boostrap Filtering
	\item Condensation Algorithm
	\item Particle Filtering
	\item Survival of the fittest
\end{itemize}

The key idea again, is to represent the \emph{posterior density} function by a limited set of samples and their importance weights, based on which estimates can be calculated. As the number of samples increases, the sampled distribution becomes an equivalent representation to the functional description of the posterior probability distribution function, and the \textbf{SIS} filter approaches the optimal Bayesian filtering estimator \cite{Ristic2004}.


The recursive nature of the \emph{SIS} algorithm, implies that the new weights describing the posterior distribution $p(\mathbf{x}_k | \mathbf{\observ}_k)$ are being updated based on their previous values, and the likelihood of a new measurement $$p(\mathbf{\observ}_k | \mathbf{x}_k^i)$$, i.e.

\begin{equation}\label{eq:SIS}
w_k^i \sim w_{k-1}^i \frac{p(\mathbf{\observ}_k | \mathbf{x}_k^i)p(\mathbf{x}_k^i | \mathbf{x}_{k-1}^i)}{q(\mathbf{x}_k^i | \mathbf{x}_{k-1}^i , \mathbf{\observ}_k)}
\end{equation}


Then the posterior filtered density is approximated by a probability mass function in \Cref{eq:posterior_pmf}

\begin{equation}\label{eq:posterior_pmf}
p(\mathbf{x}_k | \mathbf{\observ}_k) \approx \sum_{i=1}^N w_k^i \delta(\mathbf{x}_k - \mathbf{x}_k^i)
\end{equation}


The recursiveness of the SIS algorithm is evident from the fact that the importance weights $w_k^i$ and support points $x_k^i$ are being propagated as each measurement is received sequentially. The SIS algorithm is the basis of most particle filtering algorithms, and the choice of the importance density function is crucial in the design's performance.

\subsection{Selecting the Importance Density}

A popular and convenient selection of the importance density is the transitional prior, i.e. the motion model \cite{Ristic2004}:

\begin{equation}\label{eq:SISmotmodel}
q(\mathbf{x}_k | \mathbf{x}_{k-1}^i , \mathbf{\observ}_k) = p(\mathbf{x}_k | \mathbf{x}_{k-1}^i)
\end{equation}

substituting \Cref{eq:SISmotmodel} in the **SIS** algorithm(\Cref{eq:SIS}) yields \Cref{eq:SIS2}

\begin{equation}\label{eq:SIS2}
 w_k^i \sim w_{k-1}^i p(\mathbf{\observ}_k | \mathbf{x}_k^i)
\end{equation}


\subsection{Degeneracy problem}

A general problem of a SIS particle filter is that the particle distribution becomes extremely peaked through the subsequent measurement updates. That is, the variance of the importance weights can only increase over time. This effect overtime leads to poor accuracy of the estimates and leads to a common problem of the SIS particle filter, that of \emph{degeneracy}. An effective countermeasure is monitoring the level of degeneracy of the filter and re-sample when appropriate. An example of a performance index is the effective sample size $N_{\text{eff}}$ as introduced by \cite{Kong1994}


\begin{equation}
\hat{N}_{\text{eff}} = \frac{1}{\sum_{i=1}^{N}(w_k^i)^2}
\end{equation}


One can easily verify that $$1 < N_{\text{eff}} < N$$ , the degeneracy criterion is thus as in \Cref{eq:criterion_degeneracy}

\begin{equation}\label{eq:criterion_degeneracy}
\begin{aligned}
&N_{\text{eff}} < \alpha N \\&\alpha \in \mathcal{R}: \alpha \in (0,1)
\end{aligned}
\end{equation}

\subsection{Resampling algorithms}


Whenever filter degeneracy is detected(i.e $N_{\text{eff}}$ falling below a threshold value), re-sampling is performed.


Re-sampling follows the strategy of \emph{survival of the fittest}, by eliminating particles in the set with low weight values and replacing them with copies of the more probable ones.


The re-sampling algorithm is thus \cite{Ristic2004}:

\begin{enumerate}
	\item Normalize the particle set weights $w^j$
	\item Calculate the \emph{Cumulative Sum of Weights}(CSW) function
	\item Draw $N$ random samples $u_i \in \mathcal{R}$, $i=1,..,N$ uniformly distributed on the interval $[0,1]$.
	\item For every uniform sample $u_i$, pick $\hat{x}_k^i = x_k^j$ out of the current samples pool, where the picking index $j$ depends on the weight's value as \[ j = \underset{i}{\arg\min} |{F_k(i)-u_i}| \]

\end{enumerate}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\textwidth]{/Users/dimda/static_web/static/thesis/stratified_resampling.png}
	\caption{Re-sampling process based on Cumulative Sum. The particle $x_{k_j}$ has a good chance of surviving.}.
	\label{fig:CSW}
\end{figure}


The above strategy leads to a weight selection \emph{survival chance} equal to the \emph{weight's value}
$$P(\hat{x}_k^i = x_k^j) = w_k^j$$ This results in useful samples having a higher likelihood of being selected for the new set(\Cref{fig:CSW}). The new weights of the samples are re-initialized to a uniform distribution

\begin{equation}\label{eq:normalize2CSW}
	\{\hat{x}_k^i , 1/N\}
\end{equation}



The use of re-sampling technique might lead to different issues though. \emph{Diversity} among particles is depleted as highly probable particles are through subsequent re-sampling steps \emph{genetically dominating} the distribution. Moreover, if the process noise is too low then the distribution will not \emph{diversify} enough in between measurement updates and will eventually become a uniformly weighted cloned collection of a few particles. This phenomenon is also known as \emph{sample impoverishment} or \emph{particle depletion} \Cref{fig:impoverishment} \cite{Chatzi2002}.

% TODO: \usepackage{graphicx} required
\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\linewidth]{../../../../static_web/static/thesis/impoverishment}
	\caption{Particles impoverishment \cite{Ju2019}}
	\label{fig:impoverishment}
\end{figure}


\subsection{PF Algorithm outline}


The PF algorithm genetics are illustrated in \Cref{fig:PF_genetics} and summarized as follows

\begin{enumerate}
	\item Initialize the filter by drawing particles according to an initial belief $p(\mathbf{x}_0)$.\\
	
	Usually  $p(\mathbf{x}_0)$ is Gaussian with known moments, or a uniform distribution around the initial estimate  $\mathbf{x}_{0}$.
	
	\item Update the particle set weights according to a the likelihood of the new measurement.\\
	
	This step requires point-wise evaluation of the likelihood-function $p(\mathbf{\observ}_k | \mathbf{x}_k)$ which depends on the stochastic properties, of the \emph{measurement model}.\\
	
	Example: For the radar sensor, the likelihood function is the \emph{multivariate Gaussian}:
	$$
	p(\observ|x) = (2\pi)^{-\frac{k}{2}}\det{}(\mathbf{R})e^{-\frac{1}{2}\left(\observ-h(x))^{T}\mathbf{R}(\observ-h(x)\right)}
	$$
	Where $\mathbf{R}_{k\times k}$ is the measurement noise covariance matrix
	
	
	\item Normalize weights to represent a PMF.
	\item Re-sample if required, based on $N_{\text{eff}} < \textit{threshold}$
	\item Propagate every point according to the motion model.
	
	It is crucial to use non-zero process noise at that step, as that ensures that additional diversity is being introduced into the distribution.
	
	\item Repeat from step 2.
\end{enumerate}



\begin{figure}[H]
	\centering
	\includegraphics[width=0.8\textwidth]{/Users/dimda/static_web/static/thesis/particle_filter_genetics.png}
	\caption{General particle filtering algorithm genetics \cite{Chatzi2002}.}
	\label{fig:PF_genetics}
\end{figure}

